{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stirl\\miniconda3\\envs\\network_env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from fun.fun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START\n",
    "edges_csv = \"../data/edges.csv\"\n",
    "edges_prq = \"../data/edges.parquet\"\n",
    "edges_total = 684_732_453 # hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading edges ... read 684_732_453 lines (took 0.1s)\n",
      "source    int32\n",
      "target    int32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>103151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103151</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>138731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>42023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0      13  103151\n",
       "1      13  214293\n",
       "2  103151  214293\n",
       "3      13  138731\n",
       "4      13   42023"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> IN : PARQUET Read edges from parquet to dataframe\n",
    "print(\"reading edges ... \", end='')\n",
    "start = time.time()\n",
    "df = dd.read_parquet(edges_prq)\n",
    "df[['source', 'target']] = df[['source', 'target']].astype('int32')\n",
    "end = time.time()\n",
    "print(\"read {:_} lines (took {:.1f}s)\".format(len(df), (end-start)))\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 410_885\n"
     ]
    }
   ],
   "source": [
    "# -> IN : Read list of nodes\n",
    "nodes = pd.read_csv('../data/node_ids.csv', index_col='index')\n",
    "print(\"Number of nodes: {:_}\".format(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating iGraph ...\n",
      "Processing 157 partitions ...\n",
      " partitions processed: 75/157 (47.77070%)"
     ]
    }
   ],
   "source": [
    "# (1) GRAPH (ALL EDGES) : Loading edges into iGraph\n",
    "print(\"Creating iGraph ...\")\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(nodes))\n",
    "print(\"Processing {} partitions ...\".format(df.npartitions))\n",
    "for i, partition in enumerate(df.to_delayed()):\n",
    "    p_df = partition.compute()\n",
    "    g.add_edges(p_df.values.tolist())\n",
    "    _, perc = track_progress(df.npartitions, i, text=\"partitions processed:\")\n",
    "    #if perc > 1: break\n",
    "    #if input(\"...\") == 'b': break\n",
    "    #if i+1 >= 10: break\n",
    "print(\"\\nDone.\")\n",
    "print(\"\\nGRAPH CREATED:\")\n",
    "print(\"  nodes: {:_}\".format(len(g.vs)))\n",
    "print(\"  edges: {:_}\".format(len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) GRAPH (N EDGES) : Loading edges into iGraph\n",
    "nrows = 4_000_000 # max: 4557647\n",
    "#nrows = 100 # max: 4557647\n",
    "g = ig.Graph.TupleList(df.head(nrows).values.tolist())\n",
    "print(\"\\nGRAPH CREATED:\")\n",
    "print(\"  nodes: {:_}\".format(len(g.vs)))\n",
    "print(\"  edges: {:_}\".format(len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average path length\n",
    "# 6 partitions (3.8%) 16m 40s\n",
    "# \n",
    "apl = g.average_path_length()\n",
    "print(\"Average path length: {:.3f}\".format(apl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get graph diameter\n",
    "diam = g.diameter()\n",
    "print(\"Diameter of graph:\", diam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and save adjacency matrix (as sparse CSC matrix)\n",
    "adj_matrix_sparse_fn = '../data/adjacency_matrix_sparce.npz'\n",
    "adj_matrix_sparse = g.get_adjacency_sparse()\n",
    "sp.sparse.save_npz(adj_matrix_sparse_fn, adj_matrix_sparse) # save CSC matrix\n",
    "#sparse_matrix = sp.sparse.load_npz(adj_matrix_sparse_fn) # load CSC matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degree centrality of graph\n",
    "dc_fn = '../data/degree_centralities.csv'\n",
    "dc = g.degree()\n",
    "print(\"DEGREE CENTRALITY\")\n",
    "print(\"len: {:_}\".format(len(dc)))\n",
    "print(\"max: {:_}\".format(max(dc)))\n",
    "print(\"min: {}\".format(min(dc)))\n",
    "print(\"mean: {:.1f}\".format(np.mean(dc)))\n",
    "dc_df = pd.DataFrame(dc)\n",
    "dc_df.to_csv(dc_fn, index=False, header=False)\n",
    "plt.hist(dc, bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
