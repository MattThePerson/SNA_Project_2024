{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stirl\\miniconda3\\envs\\network_env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from fun.fun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START\n",
    "edges_csv = \"../data/edges.csv\"\n",
    "edges_prq = \"../data/edges.parquet\"\n",
    "edges_total = 684_732_453 # hardcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading edges ... read 684_732_453 lines (took 0.2s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>103151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103151</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>138731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>42023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0      13  103151\n",
       "1      13  214293\n",
       "2  103151  214293\n",
       "3      13  138731\n",
       "4      13   42023"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> IN : PARQUET Read edges from parquet to dataframe\n",
    "print(\"reading edges ... \", end='')\n",
    "start = time.time()\n",
    "df = dd.read_parquet(edges_prq)\n",
    "end = time.time()\n",
    "print(\"read {:_} lines (took {:.1f}s)\".format(len(df), (end-start)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP : Get number of unique nodes in df\n",
    "nodes = set(df['source']).union(set(df['target']))\n",
    "num_nodes = len(nodes)\n",
    "print(f\"{num_nodes:_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 410_885\n"
     ]
    }
   ],
   "source": [
    "# -> IN : Read list of nodes\n",
    "nodes = pd.read_csv('../data/node_ids.csv', index_col='index')\n",
    "print(\"Number of nodes: {:_}\".format(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating iGraph ...\n",
      "Processing 157 partitions ...\n",
      " partitions processed: 130/157 (82.80255%)"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error at src/core/vector.c:475: Cannot reserve space for vector. -- Out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, partition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df\u001b[38;5;241m.\u001b[39mto_delayed()):\n\u001b[0;32m      7\u001b[0m     p_df \u001b[38;5;241m=\u001b[39m partition\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     _, perc \u001b[38;5;241m=\u001b[39m track_progress(df\u001b[38;5;241m.\u001b[39mnpartitions, i, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartitions processed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#if perc > 1: break\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#if input(\"...\") == 'b': break\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#if i+1 >= 10: break\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stirl\\miniconda3\\envs\\network_env\\Lib\\site-packages\\igraph\\basic.py:42\u001b[0m, in \u001b[0;36m_add_edges\u001b[1;34m(graph, es, attributes)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Adds some edges to the graph.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m@param es: the list of edges to be added. Every edge is represented\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m  edges.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m eid \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mecount()\n\u001b[1;32m---> 42\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mGraphBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m n \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mecount() \u001b[38;5;241m-\u001b[39m eid\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error at src/core/vector.c:475: Cannot reserve space for vector. -- Out of memory"
     ]
    }
   ],
   "source": [
    "# (1) GRAPH (ALL EDGES) : Loading edges into iGraph\n",
    "print(\"Creating iGraph ...\")\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(nodes))\n",
    "print(\"Processing {} partitions ...\".format(df.npartitions))\n",
    "for i, partition in enumerate(df.to_delayed()):\n",
    "    p_df = partition.compute()\n",
    "    g.add_edges(p_df.values.tolist())\n",
    "    _, perc = track_progress(df.npartitions, i, text=\"partitions processed:\")\n",
    "    #if perc > 1: break\n",
    "    #if input(\"...\") == 'b': break\n",
    "    #if i+1 >= 10: break\n",
    "print(\"\\nDone.\")\n",
    "print(\"\\nGRAPH CREATED:\")\n",
    "print(\"  nodes: {:_}\".format(len(g.vs)))\n",
    "print(\"  edges: {:_}\".format(len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) GRAPH (N EDGES) : Loading edges into iGraph\n",
    "nrows = 4_000_000 # max: 4557647\n",
    "#nrows = 100 # max: 4557647\n",
    "g = ig.Graph.TupleList(df.head(nrows).values.tolist())\n",
    "print(\"\\nGRAPH CREATED:\")\n",
    "print(\"  nodes: {:_}\".format(len(g.vs)))\n",
    "print(\"  edges: {:_}\".format(len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and save adjacency matrix (as sparse CSC matrix)\n",
    "adj_matrix_sparse_fn = '../data/adjacency_matrix_sparce.npz'\n",
    "adj_matrix_sparse = g.get_adjacency_sparse()\n",
    "sp.sparse.save_npz(adj_matrix_sparse_fn, adj_matrix_sparse) # save CSC matrix\n",
    "#sparse_matrix = sp.sparse.load_npz(adj_matrix_sparse_fn) # load CSC matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get degree centrality of graph\n",
    "dc_fn = '../data/degree_centralities.csv'\n",
    "dc = g.degree()\n",
    "print(\"DEGREE CENTRALITY\")\n",
    "print(\"len: {:_}\".format(len(dc)))\n",
    "print(\"max: {:_}\".format(max(dc)))\n",
    "print(\"min: {}\".format(min(dc)))\n",
    "print(\"mean: {:.1f}\".format(np.mean(dc)))\n",
    "dc_df = pd.DataFrame(dc)\n",
    "dc_df.to_csv(dc_fn, index=False, header=False)\n",
    "plt.hist(dc, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average path length\n",
    "# 6 partitions (3.8%) 16m 40s\n",
    "# \n",
    "apl = g.average_path_length()\n",
    "print(\"Average path length: {:.3f}\".format(apl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get graph diameter\n",
    "diam = g.diameter()\n",
    "print(\"Diameter of graph:\", diam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
