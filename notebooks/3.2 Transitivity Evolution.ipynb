{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stirl\\miniconda3\\envs\\network_env\\Lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Functions: Analyse the evoltion of average positive and negative\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from fun.fun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames\n",
    "dataset_fn = \"../dataset/TweetsCOV19.tsv\"\n",
    "plot_fn = \"../images/plots/transitivity_evolution.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading edges ... read 684_732_453 lines (took 0.1s)\n",
      "source    int64\n",
      "target    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>103151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103151</td>\n",
       "      <td>214293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>138731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>42023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target\n",
       "0      13  103151\n",
       "1      13  214293\n",
       "2  103151  214293\n",
       "3      13  138731\n",
       "4      13   42023"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> IN : Read Edge List\n",
    "edges_fn = \"../data/edges.parquet\"\n",
    "print(\"reading edges ... \", end='')\n",
    "start = time.time()\n",
    "df = dd.read_parquet(\"../data/edges.parquet\")\n",
    "df[['source', 'target']], df[['source', 'target']].astype('int32')\n",
    "end = time.time()\n",
    "print(\"read {:_} lines (took {:.1f}s)\".format(len(df), (end-start)))\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adjacency matrix\n",
    "nodes = dd.concat([df['source'], df['target']]).unique().compute()\n",
    "num_nodes = len(nodes)\n",
    "print(\"found {:_} unique nodes\".format(num_nodes))\n",
    "\n",
    "adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "for i, j in df.values:\n",
    "    adj_matrix[i, j] = 1\n",
    "    adj_matrix[j, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset from tsv file ..."
     ]
    }
   ],
   "source": [
    "# -> IN : Load tweets dataframe\n",
    "tw = get_filtered_tweets_dataframe(dataset_fn)\n",
    "print(\"Loaded {:_} tweets\".format(len(tw)))\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 410_885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200927495186505729</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200927503201816576</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200927507828097026</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200927511087067136</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200927514216062976</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     index\n",
       "twitter id                \n",
       "1200927495186505729      0\n",
       "1200927503201816576      1\n",
       "1200927507828097026      2\n",
       "1200927511087067136      3\n",
       "1200927514216062976      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> IN : Read list of nodes\n",
    "nodes = pd.read_csv('../data/node_ids.csv', index_col='twitter id')\n",
    "print(\"Number of nodes: {:_}\".format(len(nodes)))\n",
    "nodes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH (ALL EDGES) : Loading edges into iGraph\n",
    "print(\"Creating iGraph ...\")\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(nodes))\n",
    "print(\"Processing {} partitions ...\".format(df.npartitions))\n",
    "for i, partition in enumerate(df.to_delayed()):\n",
    "    p_df = partition.compute()\n",
    "    g.add_edges(p_df.values.tolist())\n",
    "    _, perc = track_progress(df.npartitions, i, text=\"partitions processed:\")\n",
    "    #if perc > 1: break\n",
    "    #if input(\"...\") == 'b': break\n",
    "    if i+1 >= 5: break\n",
    "print(\"\\nDone.\")\n",
    "print(\"\\nGRAPH CREATED:\")\n",
    "print(\"  nodes: {:_}\".format(len(g.vs)))\n",
    "print(\"  edges: {:_}\".format(len(g.es)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transitivity\n",
    "glob_transitivity = g.transitivity_undirected()\n",
    "print(glob_transitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "n = 410000\n",
    "triplets = comb(n,3)\n",
    "triangles = glob_transitivity * triplets\n",
    "print(f\"{triplets:_}\")\n",
    "print(f\"{triangles:_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min timestamp: 2019-12-01 00:00:01+00:00\n",
      "Max timestamp: 2020-02-29 23:59:49+00:00\n",
      "Timestamp increment: 0 days 21:50:23.880000\n"
     ]
    }
   ],
   "source": [
    "# Compute timestamp bins\n",
    "increments = 100\n",
    "ts_min, ts_max = min(tw['Timestamp']), max(tw['Timestamp'])\n",
    "ts_inc = (ts_max - ts_min) / 100\n",
    "ts_bins = [ ts_min + (i+1)*ts_inc for i in range(increments) ]\n",
    "\n",
    "print(\"Min timestamp:\", ts_min)\n",
    "print(\"Max timestamp:\", ts_max)\n",
    "print(\"Timestamp increment:\", ts_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute average cumulative sentiment for timestamp increments\n",
    "ts = ts_min + 10*ts_inc\n",
    "tweets = tw[tw['Timestamp'] < ts]\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
