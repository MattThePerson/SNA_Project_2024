{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines (tweets): 8_151_524\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distribution(values, one_width_bins=False):\n",
    "    values = np.array(values)\n",
    "    if one_width_bins:  bins = range(min(values), max(values) + 1, 1)\n",
    "    else:               bins = 25\n",
    "    print(\"\\nSTATS:\")\n",
    "    print(\"max: {:_}\".format(max(values)))\n",
    "    print(\"mean: {:.2f}\".format(np.mean(values)))\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(10,4))\n",
    "    ax[0].hist(values, bins=bins)\n",
    "    ax[0].set_title('Histogram of amount of mentions per tweet')\n",
    "    ax[1].hist(values, log=True, bins=bins)\n",
    "    ax[1].set_title('Logarithmic Histogram of amount of mentions per tweet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8077794, 13)\n",
      "              Tweet Id                          Username                       Timestamp  Followers  Friends  Retweets  Favorites                                           Entities Sentiment Mentions Hashtags                                               URLs EXTRA\n",
      "0  1178791787386814465  35234fe4a19cc1a3336095fb3780bcc1  Mon Sep 30 22:00:37 +0000 2019        619      770         0          0                                              null;      2 -1    null;    null;                                              null;  <NA>\n",
      "1  1178791985106153472  ea4592f39636d87af8fb4b17b7e2e4c0  Mon Sep 30 22:01:24 +0000 2019      36365    19344        13         17  nazi:Nazism:-2.742538749414189;blood money:Blo...      1 -4    null;    null;  https://twitter.com/himalayahawk/status/117766...  <NA>\n",
      "2  1178793230223183872  bf05d1888dd974fa4a8679c25e2ead03  Mon Sep 30 22:06:21 +0000 2019       5018     1933         0          0  vaccine:Vaccine:-2.6651530673745762;anti vaxxe...      2 -1    null;    null;                        https://goo.gl/fb/uoeiPk:-:  <NA>\n",
      "3  1178795172206919680  eb8a99bca8945eab1d006750e9b75518  Mon Sep 30 22:14:04 +0000 2019       2219      971         0          0  muse:Muse_%28band%29:-2.1677823918620867;talki...      2 -1    null;    null;                                              null;  <NA>\n",
      "4  1178798309491822592  00695cf79d60e86a5d0f872f4358337a  Mon Sep 30 22:26:32 +0000 2019       9009     4943        26         89  people of northern ireland:People_of_Northern_...      2 -1    null;      VFS                                              null;  <NA>\n",
      "                    Tweet Id                          Username                       Timestamp  Followers  Friends  Retweets  Favorites                                           Entities Sentiment                   Mentions                    Hashtags                                               URLs EXTRA\n",
      "8077789  1255977575806939136  d304c5f831a28e2a46ce1103cc8a40f2  Thu Apr 30 21:49:23 +0000 2020         45      236         0          0             bbc news:BBC_News:-0.4189977366734566;      1 -1                      null;                       null;  https://www.bbc.com/news/world-us-canada-52493...  <NA>\n",
      "8077790  1255978146228318208  ad97147abec2ec6fe2e575f36264a33e  Thu Apr 30 21:51:39 +0000 2020          5       74         0          0                                              null;      3 -1                      null;  almost lockdown itvtonight                                              null;  <NA>\n",
      "8077791  1255978188267614208  c456c71a9e4d054714e2ca58c3d93fa2  Thu Apr 30 21:51:49 +0000 2020      46987     4953        38        125  free will:Free_will:-1.9738137854232647;there ...      2 -3                      null;                       null;                                              null;  <NA>\n",
      "8077792  1255979266115854336  bde2cd85338f0b68303e4702ff562557  Thu Apr 30 21:56:06 +0000 2020      21796    22109         0          0  social distancing:Social_distancing:-1.4103273...      1 -2                      null;                       null;                                              null;  <NA>\n",
      "8077793  1255979706513580036  a2a2726de83b4afaa8622efd50906e38  Thu Apr 30 21:57:51 +0000 2020         25      203         0          0                                              null;      2 -1  kylerobertsxx shanedawson                       null;                                              null;  <NA>\n"
     ]
    }
   ],
   "source": [
    "# Import dataset from tsv file\n",
    "dataset_fn = \"../dataset/TweetsCOV19.tsv\"\n",
    "header = [\"Tweet Id\", \"Username\", \"Timestamp\", \"Followers\", \"Friends\", \"Retweets\", \"Favorites\", \"Entities\", \"Sentiment\", \"Mentions\", \"Hashtags\", \"URLs\", \"EXTRA\"]\n",
    "dtype = {\"Tweet Id\":\"string\", \"Username\":\"string\", \"Timestamp\":\"string\", \"Followers\":int, \"Friends\":int, \"Retweets\":int, \"Favorites\":int, \"Entities\":\"string\", \"Sentiment\":\"string\", \"Mentions\":\"string\", \"Hashtags\":\"string\", \"URLs\":\"string\", \"EXTRA\":\"string\"}\n",
    "df = pd.read_csv(dataset_fn, sep='\\t', names=header, on_bad_lines='warn', dtype=dtype)\n",
    "#df.set_index('Tweet Id', inplace=True)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Tweet Id                          Username                 Timestamp  Followers  Friends  Retweets  Favorites                                           Entities Sentiment Mentions Hashtags                                               URLs EXTRA\n",
      "0  1178791787386814465  35234fe4a19cc1a3336095fb3780bcc1 2019-09-30 22:00:37+00:00        619      770         0          0                                              null;      2 -1    null;    null;                                              null;  <NA>\n",
      "1  1178791985106153472  ea4592f39636d87af8fb4b17b7e2e4c0 2019-09-30 22:01:24+00:00      36365    19344        13         17  nazi:Nazism:-2.742538749414189;blood money:Blo...      1 -4    null;    null;  https://twitter.com/himalayahawk/status/117766...  <NA>\n",
      "2  1178793230223183872  bf05d1888dd974fa4a8679c25e2ead03 2019-09-30 22:06:21+00:00       5018     1933         0          0  vaccine:Vaccine:-2.6651530673745762;anti vaxxe...      2 -1    null;    null;                        https://goo.gl/fb/uoeiPk:-:  <NA>\n",
      "3  1178795172206919680  eb8a99bca8945eab1d006750e9b75518 2019-09-30 22:14:04+00:00       2219      971         0          0  muse:Muse_%28band%29:-2.1677823918620867;talki...      2 -1    null;    null;                                              null;  <NA>\n",
      "4  1178798309491822592  00695cf79d60e86a5d0f872f4358337a 2019-09-30 22:26:32+00:00       9009     4943        26         89  people of northern ireland:People_of_Northern_...      2 -1    null;      VFS                                              null;  <NA>\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp column to Timestamp object\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%a %b %d %H:%M:%S %z %Y')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848756, 5)\n",
      "                    Tweet Id                          Username                 Timestamp Sentiment            Hashtags\n",
      "1195416  1200927583271030784  627c14506ce54401df4ad0184df89a66 2019-12-01 00:00:22+00:00      1 -2               null;\n",
      "1195417  1200928806757752833  83c182d0ee195dc692900d7ff7328171 2019-12-01 00:05:14+00:00      1 -2  rgvwx rgv txwx spi\n",
      "1195418  1200928995275137025  4f148150c84a100f3e950bb74c06f12a 2019-12-01 00:05:59+00:00      1 -1               null;\n",
      "1195419  1200929150783119360  402f2270b569a804ccefd169343c81c4 2019-12-01 00:06:36+00:00      1 -3               null;\n",
      "1195420  1200931078585737216  7736b705a55eed087b05cad37e3cbcd0 2019-12-01 00:14:16+00:00      1 -1               null;\n"
     ]
    }
   ],
   "source": [
    "# Filter columns and timestamp\n",
    "dff = df[[\"Tweet Id\", \"Username\", \"Timestamp\", \"Sentiment\", \"Hashtags\"]]\n",
    "start_date =    pd.to_datetime('2019-12-01 00:00:00 +0000')\n",
    "end_date =      pd.to_datetime('2020-03-01 00:00:00 +0000')\n",
    "dff = dff[(dff['Timestamp'] >= start_date) & (dff['Timestamp'] < end_date)]\n",
    "print(dff.shape)\n",
    "print(dff.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse hashtags and mentions tab into array\n",
    "#dff['Mentions'] = dff['Mentions'].str.split().apply(lambda x: [name for name in x if name != \"null;\"] if isinstance(x, list) else [])\n",
    "dff['Hashtags'] = dff['Hashtags'].str.split().apply(lambda x: [name for name in x if name != \"null;\"] if isinstance(x, list) else [])\n",
    "\n",
    "# Split positive and negative sentiments into own columns (and convert to int type)\n",
    "dff[['Sentiment_pos', 'Sentiment_neg']] = dff['Sentiment'].str.split(\" \", expand=True)\n",
    "dff['Sentiment_pos'], dff['Sentiment_neg'] = dff['Sentiment_pos'].astype(int), dff['Sentiment_neg'].astype(int)\n",
    "dff.drop(\"Sentiment\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462901, 5)\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with mentions (and less that outlier mentions)\n",
    "with_hashtags = dff[dff['Hashtags'].apply(lambda x: len(x) > 0 and len(x) < 60)]\n",
    "print(with_hashtags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of amount of hashtags per tweet\n",
    "print(\"Extracting amount of hashtags ...\")\n",
    "hashtags_n = np.array(with_hashtags['Hashtags'].apply(lambda x: len(set(x))))\n",
    "print(\"Sorting ...\")\n",
    "hashtags_n = sorted(hashtags_n, reverse=True)\n",
    "print(\"Showing distribution ...\")\n",
    "show_distribution(hashtags_n, one_width_bins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweet ids for each hashtag\n",
    "df = with_hashtags\n",
    "array_col, id_col = \"Hashtags\", \"Tweet Id\"\n",
    "dict = {}\n",
    "print(\"Getting list of ids per hashtag ...\")\n",
    "i = 0\n",
    "for _, row in df.iterrows():\n",
    "    i += 1\n",
    "    perc = (i) / len(df) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.1f}%)\".format(i, len(df), perc), end='')\n",
    "    for term in set(row[array_col]):\n",
    "        dict[term] = dict.get(term, []) + [row[id_col]]\n",
    "print(\"\\nDone.\")\n",
    "print(\"Found {:_} unique hashtags\".format(len(dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter mentions with more than 1 associated tweet\n",
    "dictf = { k: v for k, v in dict.items() if len(v) > 1 }\n",
    "print(\"Found {:_} hashtags with more than 1 associated tweet\".format(len(dictf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most common mentions\n",
    "keys_sorted = sorted(dict.keys(), reverse=True, key=lambda key: len(dict[key]))\n",
    "for i in range(5):\n",
    "    key = keys_sorted[i]\n",
    "    print(\"key: '{}' number of tweets: {:_}\".format(key, len(dict[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of edges that will be created\n",
    "from math import comb\n",
    "edges_n = sum([ comb(len(v),2) for v in list(dictf.values())[:-1] ])\n",
    "print(\"Number of edges that will be created: {:_}\".format(edges_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges from term:array pairs in dictf\n",
    "print(\"Creating edges ...\")\n",
    "edges_fn = \"data/edges.txt\"\n",
    "with open(edges_fn, 'w') as f:\n",
    "    edges_created = 0\n",
    "    for done, (_, ids) in enumerate(dictf.items()):\n",
    "        perc = (done+1) / len(dictf) * 100\n",
    "        print(\"\\r {:_}/{:_} ({:.3f}%) edges: {:_}\".format(done+1, len(dictf), perc, edges_created), end='')\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i+1, len(ids)):\n",
    "                line = \"{} {}\\n\".format(ids[i], ids[j])\n",
    "                f.write(line)\n",
    "                edges_created += 1\n",
    "        if perc > 0.01: break\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges from term:array pairs in dictf and save to csv file\n",
    "edges_csv_fn = \"data/edges.csv\"\n",
    "csvfile = open(edges_csv_fn, 'w', newline='')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow([\"source\", \"target\"])\n",
    "print(\"Creating edges ...\")\n",
    "for done, (_, ids) in enumerate(dictf.items()):\n",
    "    perc = (done+1) / len(dictf) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.3f}%) edges: {:_}\".format(done+1, len(dictf), perc, edges_created), end='')\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1, len(ids)):\n",
    "            #line = \"{} {}\\n\".format(ids[i], ids[j])\n",
    "            #f.write(line)\n",
    "            csvwriter.writerow([ids[i], ids[j]])\n",
    "            edges_created += 1\n",
    "    #if perc > 0.1: break\n",
    "csvfile.close()\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataframe\n",
    "import random\n",
    "df2 = pd.DataFrame()\n",
    "n = 5\n",
    "df2['id'] = [int(random.random()*10000) for _ in range(n)]\n",
    "df2['Mentions'] = [ ['a'], ['b', 'c'], ['a', 'c'], ['b', 'd'], ['e', 'd', 'a'] ]\n",
    "#print(df2)\n",
    "mentions_n = df2['Mentions'].apply(lambda x: len(x))\n",
    "mentions_n = np.array(mentions_n)\n",
    "#mentions_n = np.log(mentions_n)\n",
    "print(type(mentions_n))\n",
    "print(mentions_n)\n",
    "\n",
    "# GET DICT\n",
    "df = df2\n",
    "array_col, id_col = \"Mentions\", \"id\"\n",
    "dict = {}\n",
    "print(\"Getting list of ids per mention ...\")\n",
    "i = 0\n",
    "for _, row in df.iterrows():\n",
    "    i += 1\n",
    "    perc = (i) / len(df) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.1f}%)\".format(i, len(df), perc), end='')\n",
    "    for mention in set(row[array_col]):\n",
    "        dict[mention] = dict.get(mention, []) + [row[id_col]]\n",
    "print(\"\\nDone.\")\n",
    "print(\"Found {:_} unique mentions\".format(len(dict)))\n",
    "\n",
    "# CREATE AND SAVE EDGES\n",
    "print(\"Creating edges ...\")\n",
    "edges_fn = \"data/edges.txt\"\n",
    "with open(edges_fn, 'w') as f:\n",
    "    \n",
    "    edges = set()\n",
    "    for _, ids in dict.items():\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i+1, len(ids)):\n",
    "                edge = tuple(sorted((ids[i], ids[j])))\n",
    "                edges.add(edge)\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
