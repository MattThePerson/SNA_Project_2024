{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines (tweets): 8_151_524\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distribution(values, one_width_bins=False):\n",
    "    values = np.array(values)\n",
    "    if one_width_bins:  bins = range(min(values), max(values) + 1, 1)\n",
    "    else:               bins = 25\n",
    "    print(\"\\nSTATS:\")\n",
    "    print(\"max: {:_}\".format(max(values)))\n",
    "    print(\"mean: {:.2f}\".format(np.mean(values)))\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(10,4))\n",
    "    ax[0].hist(values, bins=bins)\n",
    "    ax[0].set_title('Histogram of amount of mentions per tweet')\n",
    "    ax[1].hist(values, log=True, bins=bins)\n",
    "    ax[1].set_title('Logarithmic Histogram of amount of mentions per tweet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from tsv file\n",
    "dataset_fn = \"dataset/TweetsCOV19.tsv\"\n",
    "header = [\"Tweet Id\", \"Username\", \"Timestamp\", \"Followers\", \"Friends\", \"Retweets\", \"Favorites\", \"Entities\", \"Sentiment\", \"Mentions\", \"Hashtags\", \"URLs\", \"EXTRA\"]\n",
    "dtype = {\"Tweet Id\":\"string\", \"Username\":\"string\", \"Timestamp\":\"string\", \"Followers\":int, \"Friends\":int, \"Retweets\":int, \"Favorites\":int, \"Entities\":\"string\", \"Sentiment\":\"string\", \"Mentions\":\"string\", \"Hashtags\":\"string\", \"URLs\":\"string\", \"EXTRA\":\"string\"}\n",
    "df = pd.read_csv(dataset_fn, sep='\\t', names=header, on_bad_lines='warn', dtype=dtype)\n",
    "df.set_index('Tweet Id', inplace=True)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp column to Timestamp object\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%a %b %d %H:%M:%S %z %Y')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns and timestamp\n",
    "dff = df[[\"Username\", \"Timestamp\", \"Sentiment\", \"Hashtags\"]]\n",
    "start_date =    pd.to_datetime('2019-12-01 00:00:00 +0000')\n",
    "end_date =      pd.to_datetime('2020-03-01 00:00:00 +0000')\n",
    "dff = dff[(dff['Timestamp'] >= start_date) & (dff['Timestamp'] < end_date)]\n",
    "print(dff.shape)\n",
    "print(dff.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse hashtags and mentions tab into array\n",
    "#dff['Mentions'] = dff['Mentions'].str.split().apply(lambda x: [name for name in x if name != \"null;\"] if isinstance(x, list) else [])\n",
    "dff['Hashtags'] = dff['Hashtags'].str.split().apply(lambda x: [name for name in x if name != \"null;\"] if isinstance(x, list) else [])\n",
    "\n",
    "# Split positive and negative sentiments into own columns (and convert to int type)\n",
    "dff[['Sentiment_pos', 'Sentiment_neg']] = dff['Sentiment'].str.split(\" \", expand=True)\n",
    "dff['Sentiment_pos'], dff['Sentiment_neg'] = dff['Sentiment_pos'].astype(int), dff['Sentiment_neg'].astype(int)\n",
    "dff.drop(\"Sentiment\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with mentions (and less that outlier mentions)\n",
    "with_hashtags = dff[dff['Hashtags'].apply(lambda x: len(x) > 0 and len(x) < 60)]\n",
    "print(with_hashtags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of amount of hashtags per tweet\n",
    "print(\"Extracting amount of hashtags ...\")\n",
    "hashtags_n = np.array(with_hashtags['Hashtags'].apply(lambda x: len(set(x))))\n",
    "print(\"Sorting ...\")\n",
    "hashtags_n = sorted(hashtags_n, reverse=True)\n",
    "print(\"Showing distribution ...\")\n",
    "show_distribution(hashtags_n, one_width_bins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweet ids for each hashtag\n",
    "df = with_hashtags\n",
    "array_col, id_col = \"Hashtags\", \"Tweet Id\"\n",
    "dict = {}\n",
    "print(\"Getting list of ids per hashtag ...\")\n",
    "i = 0\n",
    "for _, row in df.iterrows():\n",
    "    i += 1\n",
    "    perc = (i) / len(df) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.1f}%)\".format(i, len(df), perc), end='')\n",
    "    for term in set(row[array_col]):\n",
    "        dict[term] = dict.get(term, []) + [row[id_col]]\n",
    "print(\"\\nDone.\")\n",
    "print(\"Found {:_} unique hashtags\".format(len(dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter mentions with more than 1 associated tweet\n",
    "dictf = { k: v for k, v in dict.items() if len(v) > 1 }\n",
    "print(\"Found {:_} hashtags with more than 1 associated tweet\".format(len(dictf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View most common mentions\n",
    "keys_sorted = sorted(dict.keys(), reverse=True, key=lambda key: len(dict[key]))\n",
    "for i in range(5):\n",
    "    key = keys_sorted[i]\n",
    "    print(\"key: '{}' number of tweets: {:_}\".format(key, len(dict[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of edges that will be created\n",
    "from math import comb\n",
    "edges_n = sum([ comb(len(v),2) for v in list(dictf.values())[:-1] ])\n",
    "print(\"Number of edges that will be created: {:_}\".format(edges_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges from term:array pairs in dictf\n",
    "print(\"Creating edges ...\")\n",
    "edges_fn = \"data/edges.txt\"\n",
    "with open(edges_fn, 'w') as f:\n",
    "    edges_created = 0\n",
    "    for done, (_, ids) in enumerate(dictf.items()):\n",
    "        perc = (done+1) / len(dictf) * 100\n",
    "        print(\"\\r {:_}/{:_} ({:.3f}%) edges: {:_}\".format(done+1, len(dictf), perc, edges_created), end='')\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i+1, len(ids)):\n",
    "                line = \"{} {}\\n\".format(ids[i], ids[j])\n",
    "                f.write(line)\n",
    "                edges_created += 1\n",
    "        if perc > 0.01: break\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges from term:array pairs in dictf and save to csv file\n",
    "edges_csv_fn = \"data/edges.csv\"\n",
    "csvfile = open(edges_csv_fn, 'w', newline='')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow([\"source\", \"target\"])\n",
    "print(\"Creating edges ...\")\n",
    "for done, (_, ids) in enumerate(dictf.items()):\n",
    "    perc = (done+1) / len(dictf) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.3f}%) edges: {:_}\".format(done+1, len(dictf), perc, edges_created), end='')\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1, len(ids)):\n",
    "            #line = \"{} {}\\n\".format(ids[i], ids[j])\n",
    "            #f.write(line)\n",
    "            csvwriter.writerow([ids[i], ids[j]])\n",
    "            edges_created += 1\n",
    "    #if perc > 0.1: break\n",
    "csvfile.close()\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataframe\n",
    "import random\n",
    "df2 = pd.DataFrame()\n",
    "n = 5\n",
    "df2['id'] = [int(random.random()*10000) for _ in range(n)]\n",
    "df2['Mentions'] = [ ['a'], ['b', 'c'], ['a', 'c'], ['b', 'd'], ['e', 'd', 'a'] ]\n",
    "#print(df2)\n",
    "mentions_n = df2['Mentions'].apply(lambda x: len(x))\n",
    "mentions_n = np.array(mentions_n)\n",
    "#mentions_n = np.log(mentions_n)\n",
    "print(type(mentions_n))\n",
    "print(mentions_n)\n",
    "\n",
    "# GET DICT\n",
    "df = df2\n",
    "array_col, id_col = \"Mentions\", \"id\"\n",
    "dict = {}\n",
    "print(\"Getting list of ids per mention ...\")\n",
    "i = 0\n",
    "for _, row in df.iterrows():\n",
    "    i += 1\n",
    "    perc = (i) / len(df) * 100\n",
    "    print(\"\\r {:_}/{:_} ({:.1f}%)\".format(i, len(df), perc), end='')\n",
    "    for mention in set(row[array_col]):\n",
    "        dict[mention] = dict.get(mention, []) + [row[id_col]]\n",
    "print(\"\\nDone.\")\n",
    "print(\"Found {:_} unique mentions\".format(len(dict)))\n",
    "\n",
    "# CREATE AND SAVE EDGES\n",
    "print(\"Creating edges ...\")\n",
    "edges_fn = \"data/edges.txt\"\n",
    "with open(edges_fn, 'w') as f:\n",
    "    \n",
    "    edges = set()\n",
    "    for _, ids in dict.items():\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i+1, len(ids)):\n",
    "                edge = tuple(sorted((ids[i], ids[j])))\n",
    "                edges.add(edge)\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
